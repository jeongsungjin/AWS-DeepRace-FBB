Hyperparameter
Gradient descent batch size : 64
Entropy : 0.01 *이건 높을수록 무작위행동(낮은확률의 행동도 고를 확률)을 할 확률이 커짐(학습이 진행됨에따라 낮춰야됨)
Discount factor : 0.95 *이건 높을수록 생존욕구가 높아짐(보상에 이미 미래를고려해놨으면 할인계수 낮춰도됨)
Loss type : Huber
Learning rate : 0.0003 *이건 낮을수록 수정치가 낮아짐(드라마틱하게 학습안함)
Number of experience episodes between each policy-updating iteration : 20
Number of epochs : 10

___

lap1 41.515s
lap2 32.992s
lap3 31.664s
total 1m 44s

___

최적화 waypoints 따라가는게 구현이 안됨 -> 학습시간을 늘리면 되려나?
ㄴ 구현방식 : 가장 가까운 최적화 waypoint 2개 알아내서 그 두개를 이은 직선과 자동차와의 거리를 계산, 가까우면 보상 높게주기 이런식임.