2h

Gradient descent batch size 64
Entropy 0.02
Discount factor 0.9
Loss type Huber
Learning rate 0.0008
Number of experience episodes between each policy-updating iteration 20
Number of epochs 10

1
00:46.005
--
2
00:45.997
--
3
00:47.738

2:19